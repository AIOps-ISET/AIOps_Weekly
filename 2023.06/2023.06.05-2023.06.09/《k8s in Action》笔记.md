# 《k8s in Action》笔记

## 第一章 k8s介绍

这章都是概念，零散着记吧。

容器实现隔离机制：

1. Linux 命名空间，它使每个进程只看到它自己的系统视图（文件、进程、网络接口、主机名等）
2. Linux控制组，它限制了进程能使用的资源量（CPU、内存、网络带宽）

容器间的共享

![image-20230607220540001](D:\Typora image\image-20230607220540001.png)

主要是由于镜像由多层构成。不同镜像可能包含完全相同的层，镜像是基于另一个镜像构建的，构建上相当于继承？然后同时节约了存储空间，因为如果两个拥有相同层的镜像被创建容器时，相同层只被存储一次，那么不同容器就能读取相同文件，但只是只读层面的共享，他们的写是隔离不可见 的。

Kubernetes的核心功能，可以看作集群操作系统

下图是一个最简单的系统图：

![image-20230607221958150](D:\Typora image\image-20230607221958150.png)

整个系统由**一个主节点**和**若干工作节点**组成。开发者将应用列表提交到主节点，然后K8s将它们部署到集群的工作节点，全自动的，自动部署，同时开发者也可也指定一些应用必须一起运行，k8s将会把它们部署到一个工作节点。

![image-20230607222641876](D:\Typora image\image-20230607222641876.png)

Dockerfile 文件包含了一系列构建镜像时会执行的指令。

构建过程是由Docker守护进程那里进行的。

![image-20230607225059442](D:\Typora image\image-20230607225059442.png)

![image-20230607225112752](D:\Typora image\image-20230607225112752.png)

Pod包含多个容器，像一个独立的逻辑机器，有自己的ip和主机名什么的，把Pod分配到工作节点上。![image-20230608092953295](D:\Typora image\image-20230608092953295.png)

![image-20230608093121490](D:\Typora image\image-20230608093121490.png)

![image-20230608094015858](D:\Typora image\image-20230608094015858.png)

![image-20230608094107659](D:\Typora image\image-20230608094107659.png)

一个负载均衡服务可能向内对接多个Pod，外部访问Pod就是访问服务的IP，然后由服务自己去分配启用哪个Pod![image-20230608095821022](D:\Typora image\image-20230608095821022.png)

## 第三章 Pod

容器被设计为每个容器只运行一个进程，当需要多进程在一起运行时，则由多个容器构成一个Pod。

Kubernetes通过配置Docker让一个Pod内的所有容器共享相同的命名空间（由多个不同功能的命名空间构成一组），而不是每个容器有一组命名空间。

同时一个Pod内的容器共享一个Network命名空间，所以它们共享相同的IP地址和端口空间，所以一个Pod中的多个进程不能绑定到同一个端口，否则会冲突。

![image-20230608101421587](D:\Typora image\image-20230608101421587.png)

![image-20230608101805825](D:\Typora image\image-20230608101805825.png)

**为pod创建一个简单的YAML描述文件**

![image-20230608102111767](D:\Typora image\image-20230608102111767.png)

**使用kubectl create 来创建pod**

![image-20230608102332504](D:\Typora image\image-20230608102332504.png)

向Pod发送请求，除了服务，还可以通过本地端口绑定pod端口

![image-20230608103017221](D:\Typora image\image-20230608103017221.png)

**通过标签管理pod以及其它k8s资源**，比如节点

标签是一个键值对，需要保证键key是唯一的就行，下面是例子

![image-20230608103404222](D:\Typora image\image-20230608103404222.png)

然后有了标签之后通过标签选择器选择对象，可以完成一些特定的要求。

### 3.7 使用命名空间对资源分组



![image-20230608105001147](D:\Typora image\image-20230608105001147.png)

![image-20230608105010499](D:\Typora image\image-20230608105010499.png)

**这里k8s的命名空间和之前容器、Pod的Linux命名空间是不是不一样啊？**它这个命名空间可以有多个pod

k8s命名空间的创建：

![image-20230608105344139](D:\Typora image\image-20230608105344139.png)

文中最后说了句，尽管命名空间将对象分隔到不同的组，只允许你对属于特定命名空间的对象进行操作，但实际上命名空间之间并不提供对正则运行的对象的任何隔离，例如这些不同空间的pod仍然可以通信。

## 第四章 副本机制和其它控制器：部署托管的pod

### 4.1 保持pod健康

kubenetes通过自动管理看容器是否正常运行

#### 4.1.1

存活探针方式，检查容器是否还在运行，可以每个容器单独指定存活探针。

![image-20230608111727651](D:\Typora image\image-20230608111727651.png)

![image-20230608111737793](D:\Typora image\image-20230608111737793.png)

### 4.2 了解ReplicationController

下面用RC缩写表示

RC是k8s的一种资源，可确保它的pod始终保持运行状态。（监测调节机制）

RC旨在创建和管理一个pod的多个副本（replicas），这就是RC名字的由来。

![image-20230608150752437](D:\Typora image\image-20230608150752437.png)

![image-20230608150818020](D:\Typora image\image-20230608150818020.png)

创建RC同样是通过YAML

![image-20230608151253850](D:\Typora image\image-20230608151253850.png)

RC对于pod的监管是通过标签选择器来实现的，所以标签选择器的内容，和pod标签内容的更改是能够决定pod是否在RC作用域的。

RC中的pod模板如果更改只会影响后面所生成的pod副本。

### 4.3 使用ReplicaSet而不是ReplicationController

下面用RS缩写代指

通常不会直接创建RS，而是在创建更高层级的Deployment资源时自动创建它们。

RS和RC的行为完全相同，但RS的pod选择器的表达能力更强。

### 4.4 使用DaemonSet在每个节点上运行一个Pod

RS和RC都用于在k8s集群上运行部署特定数量的pod。但如果你希望pod能在集群中的每个节点上运行时，（并且每个节点都需要正好一个运行的pod实例）就要使用DaemonSet。

#### 4.4.2 使用DS只在特定的节点上运行Pod

通过节点选择器，可以使得DS只将Pod部署到特定的节点。

### 4.5 运行执行单个任务的Pod

上面的三种资源都是会持续运行任务，下面的资源是用于执行单个任务。

#### 4.5.1 介绍Job资源

Job资源允许运行**一种pod**，该pod在内部进程成功结束时，不会重启容器，任务完成就行。

如果没有内部进程没有成功结束，而是某些故障，则会重启。

#### 4.5.4 在Job中运行多个pod实例

作业可以配置为创建多个pod实例，并且以并行或串行方式运行它们。

#### 4.5.5 限制Job pod 完成任务的时间

通过配置pod属性，可以限制pod的时间。如果pod运行时间超过此时间，系统将尝试终止pod，并将Job标记为失败。

### 4.6 安排Job定期运行或在将来运行一次

就是CronJob资源

![image-20230608161858667](D:\Typora image\image-20230608161858667.png)

![image-20230608161952014](D:\Typora image\image-20230608161952014.png)

#### 4.6.2 了解计划任务的运行方式

在计划的时间内，CronJbo资源会创建Job资源，然后job资源创建od。

## 第五章 服务：让客户端发现pod并与之通信

### 5.1 介绍服务

k8s服务是一种为一组功能相同的pod提供单一不变的接入点的资源，它的IP地址和端口不会改变。客户端则通过IP和端口连接，这些连接会被路由提供到该服务的任意一个pod上。

![image-20230608221337964](D:\Typora image\image-20230608221337964.png)

![image-20230608221421718](D:\Typora image\image-20230608221421718.png)

![image-20230608221619672](D:\Typora image\image-20230608221619672.png)

同一个服务可以暴露多个端口

![image-20230608225620660](D:\Typora image\image-20230608225620660.png)

命名端口

可以将pod的端口设置别名，然后服务对接的就是别名，当端口更改时，只需要更改pod对应别名的端口号就行，服务只对接依旧对接那个别名对应的端口，不需要更改。

#### 5.1.2 服务发现

K8s为客户端（可以是pod，是否可以是别的？）提供了发现服务的IP和端口的方式。

1. 通过环境变量发现

在pod开始运行的时候，k8s会初始化一系列的环境变量指向现在存在的服务，即若创建的服务早于客户端pod则pod能通过环境变量去获取服务的IP和端口，的但在pod后创建的服务，pod就无法去知道。

2. 通过DNS发现服务

k8s-system命名空间中存在一个dns pod来作为k8s系统的dns服务器，该服务器知道系统中所有的服务，那么其它的pod就能通过在知道服务名称的情况下通过全限定域名（FQDN）来访问，而不是诉诸于环境变量。

通过FQDN可以代替ip去连接服务。

### 5.2 连接集群外部的服务

它这里原话是：不要让服务将连接重定向到集群中的pod，而是让它重定向到外部IP和端口。(PS:那这个意思是说在集群A在中创建一个服务A，然后服务A去对接到集群B中的一些pod)

#### 5.2.1 介绍服务endpoint

服务并不是和pod直接相连的。而是在两者之间存在一种endpoint的资源。

endpoint存储的是那些提供服务的pod的ip和端口（由服务的选择器构建），当客户端连接到服务时，服务代理选择这些IP和端口对中的一个，并将传入连接重定向到在该位置监听的服务器。

![image-20230609200445141](D:\Typora image\image-20230609200445141.png)

通过endpoint去关联到外部集群的pod，

### 5.3 将服务暴露给外部服务器

上面都是说集群内的服务如何被pod使用，但是还需要向外部公开某些服务。

![image-20230609200848576](D:\Typora image\image-20230609200848576.png)

![image-20230609201058263](D:\Typora image\image-20230609201058263.png)

#### 5.3.1 使用NodePort类型的服务

![image-20230609201353595](D:\Typora image\image-20230609201353595.png)

![image-20230609201414448](D:\Typora image\image-20230609201414448.png)

#### 5.3.2 通过负载均衡器将服务暴露出来

![image-20230609201649702](D:\Typora image\image-20230609201649702.png)

外部客户端访问这个这个IP就行

#### 5.3.3 了解外部连接的特性



### 5.4 通过Ingress暴露服务

![image-20230609202600468](D:\Typora image\image-20230609202600468.png)

![image-20230609202645126](D:\Typora image\image-20230609202645126.png)

![image-20230609202824454](D:\Typora image\image-20230609202824454.png)

![image-20230609203105677](D:\Typora image\image-20230609203105677-1686313865870-1.png)

![image-20230609203116038](D:\Typora image\image-20230609203116038.png)

### 5.5 pod就绪后发出信号

pod是作为服务的后端，创建pod满足标签，那么服务的pod选择器就会重定向到pod，但如果pod没有准备好，那么如何处理服务请求呢？

那么就需要服务不要把请求转发到正在启动的pod中，直到其完全准备就绪

#### 5.5.1 介绍就绪指针

![image-20230609203816619](D:\Typora image\image-20230609203816619.png)

![image-20230609203841475](D:\Typora image\image-20230609203841475.png)

![image-20230609203902854](D:\Typora image\image-20230609203902854.png)

接：才接受请求。

![image-20230609204146292](D:\Typora image\image-20230609204146292.png)

### 5.6 使用headless服务来发现独立的pod

通常，当执行服务的DNS查找时，DNS服务器会返回单个IP—服务的集群IP。但是如果告诉k8s，不需要为服务提供集群IP，那么DNS服务器将返回pod IP而不是单个服务IP。![image-20230609204929171](D:\Typora image\image-20230609204929171.png)

![image-20230609204914443](D:\Typora image\image-20230609204914443.png)

#### 5.6.2 通过DNS发现pod

就按上面的方法

#### 5.6.3 发现所有的pod——包括未就绪的pod

![image-20230609205241384](D:\Typora image\image-20230609205241384.png)

### 5.7 排除服务故障

![image-20230609205324564](D:\Typora image\image-20230609205324564.png)

5.8 本章小结

![image-20230609205432322](D:\Typora image\image-20230609205432322.png)

## 第六章 卷：将磁盘挂载到容器

![image-20230609205617081](D:\Typora image\image-20230609205617081.png)

![image-20230609205646778](D:\Typora image\image-20230609205646778.png)

![image-20230609205803340](D:\Typora image\image-20230609205803340.png)

![image-20230609205812466](D:\Typora image\image-20230609205812466.png)

### 6.1 介绍卷

![image-20230609205952899](D:\Typora image\image-20230609205952899.png)



![image-20230609212033712](D:\Typora image\image-20230609212033712.png)

卷有很多种。

### 6.2 通过卷在容器之间共享数据

![image-20230610100514226](D:\Typora image\image-20230610100514226.png)

#### 6.2.2 使用Git仓库作为存储卷

![image-20230610100640037](D:\Typora image\image-20230610100640037.png)

![image-20230610100744712](D:\Typora image\image-20230610100744712.png)

![image-20230610102038101](D:\Typora image\image-20230610102038101.png)

### 6.3 访问工作节点文件系统上的文件

![image-20230610102211638](D:\Typora image\image-20230610102211638.png)

#### 6.3.1 介绍hostPath 卷

![image-20230610102357444](D:\Typora image\image-20230610102357444.png)

![image-20230610102419703](D:\Typora image\image-20230610102419703.png)

![image-20230610102601802](D:\Typora image\image-20230610102601802.png)

### 6.4 使用持久化存储

![image-20230610102644722](D:\Typora image\image-20230610102644722.png)

![image-20230610102926894](D:\Typora image\image-20230610102926894.png)

### 6.5 从底层存储技术解耦pod

![image-20230610103327894](D:\Typora image\image-20230610103327894.png)

#### 6.5.1 介绍持久卷和持久卷声明

这两个是资源

就是集群管理员创建一些底层的持久卷，然后用户去通过持久卷声明去调用已创建的持久卷。

![image-20230610103703792](D:\Typora image\image-20230610103703792.png)

![image-20230610103621435](D:\Typora image\image-20230610103621435.png)

#### 6.5.2 创建持久卷  

就是创建的一些指令

PS：持久卷不属于任何命名空间，它跟节点一样是集群层面的资源



![image-20230610104316107](D:\Typora image\image-20230610104316107.png)

这里解释一下k8s的命名空间：

![image-20230610104643122](D:\Typora image\image-20230610104643122.png)

#### 6.5.3 通过创建持久卷声明来获取持久卷 

![image-20230610104749224](D:\Typora image\image-20230610104749224.png)

![image-20230610104901409](D:\Typora image\image-20230610104901409.png)

![image-20230610104925158](D:\Typora image\image-20230610104925158.png)

![image-20230610104955940](D:\Typora image\image-20230610104955940.png)

![image-20230610105002900](D:\Typora image\image-20230610105002900.png)

#### 6.5.4 在pod种使用持久卷声明

![image-20230610105049507](D:\Typora image\image-20230610105049507.png)

#### 6.5.5 使用持久卷和持久卷声明的好处

![image-20230610105206942](D:\Typora image\image-20230610105206942.png)

#### 6.5.6 回收持久卷

1. 手动回收

![image-20230610105417325](D:\Typora image\image-20230610105417325.png)

2. 自动回收

![image-20230610105437290](D:\Typora image\image-20230610105437290.png)

![image-20230610105511989](D:\Typora image\image-20230610105511989.png)

### 6.6 持久卷的动态卷配置

![image-20230610105638503](D:\Typora image\image-20230610105638503.png)

![image-20230610105653108](D:\Typora image\image-20230610105653108.png)

![image-20230610105853872](D:\Typora image\image-20230610105853872.png)

就相当于，之前持久卷是已经生产好的，然后这边配置是现场制作。

![image-20230610110138656](D:\Typora image\image-20230610110138656.png)

#### 6.6.3 不指定存储类的动态配置

![image-20230610110429452](D:\Typora image\image-20230610110429452.png)

![image-20230610110530642](D:\Typora image\image-20230610110530642.png)

![image-20230610110552159](D:\Typora image\image-20230610110552159.png)

### 6.7 本章小节 

![image-20230610110613504](D:\Typora image\image-20230610110613504.png)

## 第七章 ConfigMap和Secret：配置应用程序

### 7.1 配置容器化应用程序

容器化应用（就是容器）配置：

1. ![image-20230610111614733](D:\Typora image\image-20230610111614733.png)

### 7.2 向容器传递命令行参数

迄今为止，所有示例中容器运行的命令都是镜像中默认定义的。

#### 7.2.1 在Docker中定义命令与参数

容器中运行的完整指令由两部分组成:命令与参数

![image-20230610112058233](D:\Typora image\image-20230610112058233.png)